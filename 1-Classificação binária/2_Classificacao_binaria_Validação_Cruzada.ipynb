{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # Semente da aleatoriedade.\n",
    "torch.manual_seed(123)  # Para os pesos da rede começar sempre iguais (BOA PRÁTICA).\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "baseFolder = os.path.join(os.path.dirname(os.getcwd()),\"Bases\")\n",
    "\n",
    "previsoresData = os.path.join(baseFolder, \"entradas_breast.csv\")\n",
    "classeData = os.path.join(baseFolder, \"saidas_breast.csv\")\n",
    "\n",
    "previsores = pd.read_csv(previsoresData)  # Caracteristicas do tumor\n",
    "classe = pd.read_csv(classeData)  # Maligno ou benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTENDO PARA UM ARRAY NUMPY\n",
    "\n",
    "previsores = np.array(previsores, dtype='float32')\n",
    "classe = np.array(classe, dtype='float32').squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classificador_torch(nn.Module):\n",
    "    \n",
    "    #DEFININDO REDE MAIS PERSONALIZADA !\n",
    "    def __init__(self):\n",
    "        # chama o construtor da classe nn.Module para garantir \n",
    "        # que a classe pai (superclasse) seja corretamente inicializada.\n",
    "        super().__init__()\n",
    "\n",
    "        # 30 -> 16 -> 16 -> 1\n",
    "        \n",
    "        self.dense0 = nn.Linear(30, 16)  # 1° camada.\n",
    "        \"\"\"\n",
    "        Aqui, estamos inicializando os pesos da camada dense0 usando uma distribuição uniforme. Isso é feito manualmente.\n",
    "        O PyTorch já inicializa os pesos automaticamente, mas nesse caso, estamos usando uma inicialização customizada.\n",
    "        Para a utilização com o skortch isso é necessário.\n",
    "        Estamos inicializando com pesos uniformes.\n",
    "        \"\"\"\n",
    "        torch.nn.init.uniform(self.dense0.weight)\n",
    "\n",
    "        self.activation0 = nn.ReLU() # Ativação.\n",
    "        self.dense1 = nn.Linear(16, 16)\n",
    "        torch.nn.init.uniform(self.dense1.weight)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(16, 1)\n",
    "        torch.nn.init.uniform(self.dense2.weight)\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Como está em formato de classe, essa é a estrutura, precisamos fazer cada uma das camadas se comunicarem.\n",
    "        x = self.dense0(x)\n",
    "        x = self.activation0(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
    "                                                  criterion=torch.nn.BCELoss, # Como o erro será calculado\n",
    "                                                  optimizer=torch.optim.Adam,\n",
    "                                                  lr=0.001,\n",
    "                                                  optimizer__weight_decay=0.0001,\n",
    "                                                  max_epochs=100,\n",
    "                                                  batch_size=10,\n",
    "                                                  train_split=False, # Não divide em dados de treino, pois vamos fazer na póoxima etapa usando validação cruzada.\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.1094\u001b[0m  1.3299\n",
      "      2       37.1094  0.2487\n",
      "      3       37.1094  0.2635\n",
      "      4       37.1094  0.3121\n",
      "      5       37.1094  0.2207\n",
      "      6       37.1094  0.1477\n",
      "      7       37.1094  0.1308\n",
      "      8       37.1094  0.1376\n",
      "      9       37.1094  0.1306\n",
      "     10       37.1094  0.1426\n",
      "     11       37.1094  0.1218\n",
      "     12       37.1094  0.1793\n",
      "     13       37.1094  0.1933\n",
      "     14       37.1094  0.2361\n",
      "     15       37.1094  0.1785\n",
      "     16       37.1094  0.1363\n",
      "     17       37.1094  0.1142\n",
      "     18       37.1094  0.1305\n",
      "     19       37.1094  0.1446\n",
      "     20       37.1094  0.1532\n",
      "     21       37.1094  0.1653\n",
      "     22       37.1094  0.1549\n",
      "     23       37.1094  0.1216\n",
      "     24       37.1094  0.1196\n",
      "     25       \u001b[36m13.5893\u001b[0m  0.1712\n",
      "     26        \u001b[36m0.5466\u001b[0m  0.1901\n",
      "     27        \u001b[36m0.5314\u001b[0m  0.1612\n",
      "     28        \u001b[36m0.4981\u001b[0m  0.2172\n",
      "     29        \u001b[36m0.4820\u001b[0m  0.2258\n",
      "     30        \u001b[36m0.4769\u001b[0m  0.2797\n",
      "     31        \u001b[36m0.4528\u001b[0m  0.2108\n",
      "     32        \u001b[36m0.4508\u001b[0m  0.2617\n",
      "     33        \u001b[36m0.4178\u001b[0m  0.2880\n",
      "     34        \u001b[36m0.4082\u001b[0m  0.1998\n",
      "     35        \u001b[36m0.3928\u001b[0m  0.1476\n",
      "     36        0.3994  0.1502\n",
      "     37        0.4015  0.1406\n",
      "     38        \u001b[36m0.3827\u001b[0m  0.1376\n",
      "     39        0.3881  0.1182\n",
      "     40        \u001b[36m0.3820\u001b[0m  0.1236\n",
      "     41        0.3828  0.1487\n",
      "     42        0.3864  0.1683\n",
      "     43        \u001b[36m0.3690\u001b[0m  0.3132\n",
      "     44        \u001b[36m0.3559\u001b[0m  0.2456\n",
      "     45        0.3563  0.2752\n",
      "     46        \u001b[36m0.3444\u001b[0m  0.2009\n",
      "     47        \u001b[36m0.3381\u001b[0m  0.2622\n",
      "     48        0.3386  0.1732\n",
      "     49        \u001b[36m0.3310\u001b[0m  0.2726\n",
      "     50        \u001b[36m0.3245\u001b[0m  0.1627\n",
      "     51        \u001b[36m0.3184\u001b[0m  0.1972\n",
      "     52        \u001b[36m0.3176\u001b[0m  0.1362\n",
      "     53        \u001b[36m0.3151\u001b[0m  0.1466\n",
      "     54        \u001b[36m0.3103\u001b[0m  0.1532\n",
      "     55        \u001b[36m0.3092\u001b[0m  0.1146\n",
      "     56        \u001b[36m0.2956\u001b[0m  0.1758\n",
      "     57        \u001b[36m0.2903\u001b[0m  0.1520\n",
      "     58        \u001b[36m0.2886\u001b[0m  0.1679\n",
      "     59        \u001b[36m0.2836\u001b[0m  0.3067\n",
      "     60        0.2847  0.2439\n",
      "     61        \u001b[36m0.2757\u001b[0m  0.1387\n",
      "     62        0.2775  0.1266\n",
      "     63        \u001b[36m0.2711\u001b[0m  0.1166\n",
      "     64        \u001b[36m0.2674\u001b[0m  0.1251\n",
      "     65        \u001b[36m0.2614\u001b[0m  0.1125\n",
      "     66        \u001b[36m0.2586\u001b[0m  0.1295\n",
      "     67        0.2593  0.1167\n",
      "     68        0.2643  0.1511\n",
      "     69        \u001b[36m0.2578\u001b[0m  0.1771\n",
      "     70        0.2588  0.1566\n",
      "     71        \u001b[36m0.2555\u001b[0m  0.1778\n",
      "     72        \u001b[36m0.2554\u001b[0m  0.2150\n",
      "     73        \u001b[36m0.2481\u001b[0m  0.1591\n",
      "     74        \u001b[36m0.2478\u001b[0m  0.1436\n",
      "     75        \u001b[36m0.2436\u001b[0m  0.1321\n",
      "     76        \u001b[36m0.2411\u001b[0m  0.1266\n",
      "     77        0.2431  0.1205\n",
      "     78        \u001b[36m0.2328\u001b[0m  0.1581\n",
      "     79        0.2381  0.1045\n",
      "     80        0.2362  0.1207\n",
      "     81        \u001b[36m0.2281\u001b[0m  0.0975\n",
      "     82        \u001b[36m0.2241\u001b[0m  0.1216\n",
      "     83        \u001b[36m0.2220\u001b[0m  0.1150\n",
      "     84        \u001b[36m0.2209\u001b[0m  0.1136\n",
      "     85        \u001b[36m0.2166\u001b[0m  0.1185\n",
      "     86        \u001b[36m0.2106\u001b[0m  0.1366\n",
      "     87        \u001b[36m0.2057\u001b[0m  0.2011\n",
      "     88        0.2121  0.1971\n",
      "     89        \u001b[36m0.1914\u001b[0m  0.2426\n",
      "     90        0.1938  0.1402\n",
      "     91        0.2055  0.2438\n",
      "     92        \u001b[36m0.1836\u001b[0m  0.2272\n",
      "     93        \u001b[36m0.1795\u001b[0m  0.1751\n",
      "     94        \u001b[36m0.1729\u001b[0m  0.2511\n",
      "     95        \u001b[36m0.1680\u001b[0m  0.2182\n",
      "     96        \u001b[36m0.1644\u001b[0m  0.2317\n",
      "     97        0.1684  0.2032\n",
      "     98        \u001b[36m0.1557\u001b[0m  0.2232\n",
      "     99        \u001b[36m0.1545\u001b[0m  0.2132\n",
      "    100        0.1547  0.3037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.1094\u001b[0m  0.2209\n",
      "      2       37.1094  0.1166\n",
      "      3       37.1094  0.1306\n",
      "      4       37.1094  0.1611\n",
      "      5       37.1094  0.1215\n",
      "      6       37.1094  0.1145\n",
      "      7       37.1094  0.1146\n",
      "      8       37.1094  0.1255\n",
      "      9       37.1094  0.1335\n",
      "     10       37.1094  0.1858\n",
      "     11       37.1094  0.2562\n",
      "     12       37.1094  0.1886\n",
      "     13       37.1094  0.2207\n",
      "     14       37.1094  0.2001\n",
      "     15       37.1094  0.1905\n",
      "     16       37.1094  0.1746\n",
      "     17       37.1094  0.1991\n",
      "     18       37.1094  0.3059\n",
      "     19       37.1094  0.1265\n",
      "     20       37.1094  0.1356\n",
      "     21       37.1094  0.1410\n",
      "     22       37.1094  0.1405\n",
      "     23       37.1094  0.1115\n",
      "     24       37.1094  0.0835\n",
      "     25       37.1094  0.1156\n",
      "     26       \u001b[36m14.5336\u001b[0m  0.1156\n",
      "     27        \u001b[36m0.6825\u001b[0m  0.1312\n",
      "     28        \u001b[36m0.6774\u001b[0m  0.1445\n",
      "     29        \u001b[36m0.6740\u001b[0m  0.1346\n",
      "     30        \u001b[36m0.6715\u001b[0m  0.1971\n",
      "     31        \u001b[36m0.6696\u001b[0m  0.1905\n",
      "     32        \u001b[36m0.6681\u001b[0m  0.1642\n",
      "     33        \u001b[36m0.6668\u001b[0m  0.1451\n",
      "     34        \u001b[36m0.6659\u001b[0m  0.1416\n",
      "     35        \u001b[36m0.6650\u001b[0m  0.1982\n",
      "     36        \u001b[36m0.6643\u001b[0m  0.1731\n",
      "     37        \u001b[36m0.6638\u001b[0m  0.1366\n",
      "     38        \u001b[36m0.6633\u001b[0m  0.1443\n",
      "     39        \u001b[36m0.6628\u001b[0m  0.1315\n",
      "     40        \u001b[36m0.6625\u001b[0m  0.1345\n",
      "     41        \u001b[36m0.6622\u001b[0m  0.1431\n",
      "     42        \u001b[36m0.6619\u001b[0m  0.1415\n",
      "     43        \u001b[36m0.6617\u001b[0m  0.1511\n",
      "     44        \u001b[36m0.6615\u001b[0m  0.1725\n",
      "     45        \u001b[36m0.6613\u001b[0m  0.1471\n",
      "     46        \u001b[36m0.6611\u001b[0m  0.1837\n",
      "     47        \u001b[36m0.6610\u001b[0m  0.1507\n",
      "     48        \u001b[36m0.6609\u001b[0m  0.1782\n",
      "     49        \u001b[36m0.6607\u001b[0m  0.1701\n",
      "     50        \u001b[36m0.6607\u001b[0m  0.1546\n",
      "     51        \u001b[36m0.6606\u001b[0m  0.1367\n",
      "     52        \u001b[36m0.6605\u001b[0m  0.1922\n",
      "     53        \u001b[36m0.6604\u001b[0m  0.1375\n",
      "     54        \u001b[36m0.6604\u001b[0m  0.1156\n",
      "     55        \u001b[36m0.6603\u001b[0m  0.1169\n",
      "     56        \u001b[36m0.6603\u001b[0m  0.1206\n",
      "     57        \u001b[36m0.6602\u001b[0m  0.1096\n",
      "     58        \u001b[36m0.6602\u001b[0m  0.1156\n",
      "     59        \u001b[36m0.6602\u001b[0m  0.1196\n",
      "     60        \u001b[36m0.6601\u001b[0m  0.1351\n",
      "     61        \u001b[36m0.6601\u001b[0m  0.1705\n",
      "     62        \u001b[36m0.6601\u001b[0m  0.1910\n",
      "     63        \u001b[36m0.6600\u001b[0m  0.1999\n",
      "     64        \u001b[36m0.6600\u001b[0m  0.1306\n",
      "     65        \u001b[36m0.6600\u001b[0m  0.1235\n",
      "     66        \u001b[36m0.6600\u001b[0m  0.1196\n",
      "     67        \u001b[36m0.6600\u001b[0m  0.1226\n",
      "     68        \u001b[36m0.6600\u001b[0m  0.1412\n",
      "     69        \u001b[36m0.6600\u001b[0m  0.1207\n",
      "     70        \u001b[36m0.6600\u001b[0m  0.1256\n",
      "     71        \u001b[36m0.6599\u001b[0m  0.1272\n",
      "     72        \u001b[36m0.6599\u001b[0m  0.1176\n",
      "     73        \u001b[36m0.6599\u001b[0m  0.1147\n",
      "     74        \u001b[36m0.6599\u001b[0m  0.1206\n",
      "     75        \u001b[36m0.6599\u001b[0m  0.1277\n",
      "     76        \u001b[36m0.6599\u001b[0m  0.1372\n",
      "     77        \u001b[36m0.6599\u001b[0m  0.1186\n",
      "     78        \u001b[36m0.6599\u001b[0m  0.1257\n",
      "     79        \u001b[36m0.6599\u001b[0m  0.1217\n",
      "     80        \u001b[36m0.6599\u001b[0m  0.1351\n",
      "     81        \u001b[36m0.6599\u001b[0m  0.1742\n",
      "     82        \u001b[36m0.6599\u001b[0m  0.1252\n",
      "     83        \u001b[36m0.6599\u001b[0m  0.1642\n",
      "     84        \u001b[36m0.6599\u001b[0m  0.1457\n",
      "     85        \u001b[36m0.6599\u001b[0m  0.1467\n",
      "     86        \u001b[36m0.6599\u001b[0m  0.1136\n",
      "     87        \u001b[36m0.6599\u001b[0m  0.1442\n",
      "     88        \u001b[36m0.6599\u001b[0m  0.1237\n",
      "     89        \u001b[36m0.6599\u001b[0m  0.1172\n",
      "     90        \u001b[36m0.6599\u001b[0m  0.1226\n",
      "     91        \u001b[36m0.6599\u001b[0m  0.1364\n",
      "     92        \u001b[36m0.6599\u001b[0m  0.1276\n",
      "     93        \u001b[36m0.6599\u001b[0m  0.1281\n",
      "     94        \u001b[36m0.6599\u001b[0m  0.1147\n",
      "     95        \u001b[36m0.6599\u001b[0m  0.1260\n",
      "     96        \u001b[36m0.6599\u001b[0m  0.1420\n",
      "     97        \u001b[36m0.6599\u001b[0m  0.1109\n",
      "     98        \u001b[36m0.6599\u001b[0m  0.1741\n",
      "     99        \u001b[36m0.6599\u001b[0m  0.2243\n",
      "    100        \u001b[36m0.6599\u001b[0m  0.1360\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1241\n",
      "      3       37.3047  0.1276\n",
      "      4       37.3047  0.1256\n",
      "      5       37.3047  0.1167\n",
      "      6       37.3047  0.1181\n",
      "      7       37.3047  0.1216\n",
      "      8       37.3047  0.1206\n",
      "      9       37.3047  0.1146\n",
      "     10       37.3047  0.1086\n",
      "     11       37.3047  0.1392\n",
      "     12       37.3047  0.1166\n",
      "     13       37.3047  0.1486\n",
      "     14       37.3047  0.1331\n",
      "     15       37.3047  0.1275\n",
      "     16       37.3047  0.1424\n",
      "     17       37.3047  0.1615\n",
      "     18       37.3047  0.1248\n",
      "     19       37.3047  0.1295\n",
      "     20       37.3047  0.2012\n",
      "     21       37.3047  0.1406\n",
      "     22       37.3047  0.1429\n",
      "     23       37.3047  0.1206\n",
      "     24       37.3047  0.1156\n",
      "     25       37.3047  0.1116\n",
      "     26       \u001b[36m12.0718\u001b[0m  0.1146\n",
      "     27        \u001b[36m0.6235\u001b[0m  0.1231\n",
      "     28        0.6243  0.1176\n",
      "     29        \u001b[36m0.6086\u001b[0m  0.1216\n",
      "     30        \u001b[36m0.5653\u001b[0m  0.1660\n",
      "     31        0.5706  0.1356\n",
      "     32        \u001b[36m0.5596\u001b[0m  0.1346\n",
      "     33        \u001b[36m0.5521\u001b[0m  0.1531\n",
      "     34        \u001b[36m0.5418\u001b[0m  0.1666\n",
      "     35        \u001b[36m0.4872\u001b[0m  0.1346\n",
      "     36        \u001b[36m0.4783\u001b[0m  0.1292\n",
      "     37        \u001b[36m0.4510\u001b[0m  0.1651\n",
      "     38        \u001b[36m0.4477\u001b[0m  0.1307\n",
      "     39        \u001b[36m0.4327\u001b[0m  0.1481\n",
      "     40        \u001b[36m0.4212\u001b[0m  0.1146\n",
      "     41        \u001b[36m0.4046\u001b[0m  0.1215\n",
      "     42        \u001b[36m0.3942\u001b[0m  0.1481\n",
      "     43        \u001b[36m0.3803\u001b[0m  0.1266\n",
      "     44        \u001b[36m0.3697\u001b[0m  0.1746\n",
      "     45        \u001b[36m0.3587\u001b[0m  0.1555\n",
      "     46        \u001b[36m0.3479\u001b[0m  0.1838\n",
      "     47        \u001b[36m0.3379\u001b[0m  0.1287\n",
      "     48        \u001b[36m0.3312\u001b[0m  0.1570\n",
      "     49        \u001b[36m0.3262\u001b[0m  0.1422\n",
      "     50        \u001b[36m0.3202\u001b[0m  0.1659\n",
      "     51        \u001b[36m0.3147\u001b[0m  0.1469\n",
      "     52        \u001b[36m0.3077\u001b[0m  0.1505\n",
      "     53        \u001b[36m0.3037\u001b[0m  0.1643\n",
      "     54        \u001b[36m0.3002\u001b[0m  0.1136\n",
      "     55        \u001b[36m0.2969\u001b[0m  0.1306\n",
      "     56        \u001b[36m0.2934\u001b[0m  0.1961\n",
      "     57        \u001b[36m0.2890\u001b[0m  0.1651\n",
      "     58        \u001b[36m0.2850\u001b[0m  0.2669\n",
      "     59        \u001b[36m0.2813\u001b[0m  0.1586\n",
      "     60        \u001b[36m0.2774\u001b[0m  0.2222\n",
      "     61        \u001b[36m0.2760\u001b[0m  0.2890\n",
      "     62        \u001b[36m0.2728\u001b[0m  0.2017\n",
      "     63        0.2736  0.2007\n",
      "     64        0.2729  0.2264\n",
      "     65        \u001b[36m0.2725\u001b[0m  0.2811\n",
      "     66        \u001b[36m0.2722\u001b[0m  0.1256\n",
      "     67        \u001b[36m0.2661\u001b[0m  0.1326\n",
      "     68        \u001b[36m0.2574\u001b[0m  0.1657\n",
      "     69        \u001b[36m0.2533\u001b[0m  0.1893\n",
      "     70        \u001b[36m0.2489\u001b[0m  0.2076\n",
      "     71        \u001b[36m0.2417\u001b[0m  0.1493\n",
      "     72        \u001b[36m0.2376\u001b[0m  0.1602\n",
      "     73        0.2390  0.1241\n",
      "     74        \u001b[36m0.2302\u001b[0m  0.1542\n",
      "     75        \u001b[36m0.2276\u001b[0m  0.1015\n",
      "     76        \u001b[36m0.2255\u001b[0m  0.1255\n",
      "     77        \u001b[36m0.2210\u001b[0m  0.1562\n",
      "     78        \u001b[36m0.2188\u001b[0m  0.2998\n",
      "     79        \u001b[36m0.2135\u001b[0m  0.1717\n",
      "     80        \u001b[36m0.2088\u001b[0m  0.1988\n",
      "     81        \u001b[36m0.2058\u001b[0m  0.2632\n",
      "     82        \u001b[36m0.2014\u001b[0m  0.1135\n",
      "     83        \u001b[36m0.2010\u001b[0m  0.1201\n",
      "     84        \u001b[36m0.1972\u001b[0m  0.1455\n",
      "     85        \u001b[36m0.1929\u001b[0m  0.1711\n",
      "     86        \u001b[36m0.1918\u001b[0m  0.1791\n",
      "     87        \u001b[36m0.1887\u001b[0m  0.1115\n",
      "     88        \u001b[36m0.1872\u001b[0m  0.1225\n",
      "     89        \u001b[36m0.1849\u001b[0m  0.1226\n",
      "     90        \u001b[36m0.1836\u001b[0m  0.1176\n",
      "     91        \u001b[36m0.1818\u001b[0m  0.1171\n",
      "     92        0.1818  0.1235\n",
      "     93        \u001b[36m0.1799\u001b[0m  0.1463\n",
      "     94        \u001b[36m0.1778\u001b[0m  0.3020\n",
      "     95        \u001b[36m0.1766\u001b[0m  0.1823\n",
      "     96        \u001b[36m0.1746\u001b[0m  0.1631\n",
      "     97        0.1757  0.1942\n",
      "     98        0.1762  0.1546\n",
      "     99        \u001b[36m0.1726\u001b[0m  0.1870\n",
      "    100        0.1726  0.1851\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1561\n",
      "      3       37.3047  0.1786\n",
      "      4       37.3047  0.1371\n",
      "      5       37.3047  0.1691\n",
      "      6       37.3047  0.1495\n",
      "      7       37.3047  0.3138\n",
      "      8       37.3047  0.2216\n",
      "      9       37.3047  0.1118\n",
      "     10       37.3047  0.1003\n",
      "     11       37.3047  0.1436\n",
      "     12       37.3047  0.1385\n",
      "     13       37.3047  0.1230\n",
      "     14       37.3047  0.1515\n",
      "     15       37.3047  0.1183\n",
      "     16       37.3047  0.1201\n",
      "     17       37.3047  0.1166\n",
      "     18       37.3047  0.1166\n",
      "     19       37.3047  0.1265\n",
      "     20       37.3047  0.1231\n",
      "     21       37.3047  0.1205\n",
      "     22       37.3047  0.1125\n",
      "     23       37.3047  0.1156\n",
      "     24       37.3047  0.1026\n",
      "     25       37.3047  0.1016\n",
      "     26       37.3047  0.1302\n",
      "     27       37.3047  0.1451\n",
      "     28       37.3047  0.1319\n",
      "     29       37.3047  0.1206\n",
      "     30       37.3047  0.1189\n",
      "     31       37.3047  0.1186\n",
      "     32       37.3047  0.1106\n",
      "     33       37.3047  0.1016\n",
      "     34       37.3047  0.1036\n",
      "     35       37.3047  0.1175\n",
      "     36       37.3047  0.1046\n",
      "     37       37.3047  0.1102\n",
      "     38       37.3047  0.1078\n",
      "     39       37.3047  0.1086\n",
      "     40       37.3047  0.1246\n",
      "     41       37.3047  0.1206\n",
      "     42       37.3047  0.1246\n",
      "     43       37.3047  0.0996\n",
      "     44       37.3047  0.1046\n",
      "     45       37.3047  0.1171\n",
      "     46       37.3047  0.1475\n",
      "     47       37.3047  0.1588\n",
      "     48       37.3047  0.1097\n",
      "     49       37.3047  0.1202\n",
      "     50       37.3047  0.1215\n",
      "     51       37.3047  0.1211\n",
      "     52       37.3047  0.1196\n",
      "     53       37.3047  0.1116\n",
      "     54       37.3047  0.1166\n",
      "     55       37.3047  0.1135\n",
      "     56       37.3047  0.1055\n",
      "     57       37.3047  0.1156\n",
      "     58       37.3047  0.1152\n",
      "     59       37.3047  0.0986\n",
      "     60       37.3047  0.0967\n",
      "     61       37.3047  0.0926\n",
      "     62       37.3047  0.1206\n",
      "     63       37.3047  0.1056\n",
      "     64       37.3047  0.1126\n",
      "     65       37.3047  0.1216\n",
      "     66       37.3047  0.1341\n",
      "     67       37.3047  0.1843\n",
      "     68       37.3047  0.2001\n",
      "     69       37.3047  0.1287\n",
      "     70       37.3047  0.1096\n",
      "     71       37.3047  0.1165\n",
      "     72       37.3047  0.1146\n",
      "     73       37.3047  0.1116\n",
      "     74       37.3047  0.0996\n",
      "     75       37.3047  0.1028\n",
      "     76       37.3047  0.0996\n",
      "     77       37.3047  0.1255\n",
      "     78       37.3047  0.1236\n",
      "     79       37.3047  0.1346\n",
      "     80       37.3047  0.1231\n",
      "     81       37.3047  0.1275\n",
      "     82       37.3047  0.1337\n",
      "     83       37.3047  0.1301\n",
      "     84       37.3047  0.1296\n",
      "     85       37.3047  0.1435\n",
      "     86       37.3047  0.1798\n",
      "     87       37.3047  0.1425\n",
      "     88       37.3047  0.1482\n",
      "     89       37.3047  0.1812\n",
      "     90       37.3047  0.1046\n",
      "     91       37.3047  0.1166\n",
      "     92       37.3047  0.1266\n",
      "     93       37.3047  0.1221\n",
      "     94       37.3047  0.1625\n",
      "     95       37.3047  0.1280\n",
      "     96       37.3047  0.1272\n",
      "     97       37.3047  0.1276\n",
      "     98       37.3047  0.1276\n",
      "     99       37.3047  0.1251\n",
      "    100       37.3047  0.1185\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1401\n",
      "      3       37.3047  0.1734\n",
      "      4       37.3047  0.1453\n",
      "      5       37.3047  0.1519\n",
      "      6       37.3047  0.1336\n",
      "      7       37.3047  0.1245\n",
      "      8       37.3047  0.1155\n",
      "      9       37.3047  0.1226\n",
      "     10       37.3047  0.1231\n",
      "     11       37.3047  0.1186\n",
      "     12       37.3047  0.1306\n",
      "     13       37.3047  0.1206\n",
      "     14       37.3047  0.1221\n",
      "     15       37.3047  0.1296\n",
      "     16       37.3047  0.1175\n",
      "     17       37.3047  0.1624\n",
      "     18       37.3047  0.1276\n",
      "     19       37.3047  0.1315\n",
      "     20       37.3047  0.1192\n",
      "     21       37.3047  0.1495\n",
      "     22       37.3047  0.1454\n",
      "     23       37.3047  0.1369\n",
      "     24       37.3047  0.1355\n",
      "     25       37.3047  0.1320\n",
      "     26       37.3047  0.1286\n",
      "     27       \u001b[36m15.4252\u001b[0m  0.1273\n",
      "     28        \u001b[36m0.5840\u001b[0m  0.1261\n",
      "     29        \u001b[36m0.5584\u001b[0m  0.1186\n",
      "     30        \u001b[36m0.5357\u001b[0m  0.1186\n",
      "     31        \u001b[36m0.5147\u001b[0m  0.1246\n",
      "     32        \u001b[36m0.4931\u001b[0m  0.1175\n",
      "     33        \u001b[36m0.4707\u001b[0m  0.1277\n",
      "     34        \u001b[36m0.4511\u001b[0m  0.1217\n",
      "     35        \u001b[36m0.4295\u001b[0m  0.1106\n",
      "     36        \u001b[36m0.4118\u001b[0m  0.1015\n",
      "     37        \u001b[36m0.3913\u001b[0m  0.0996\n",
      "     38        \u001b[36m0.3739\u001b[0m  0.1176\n",
      "     39        \u001b[36m0.3564\u001b[0m  0.1417\n",
      "     40        \u001b[36m0.3437\u001b[0m  0.1754\n",
      "     41        \u001b[36m0.3298\u001b[0m  0.1407\n",
      "     42        \u001b[36m0.3150\u001b[0m  0.1412\n",
      "     43        \u001b[36m0.2950\u001b[0m  0.1332\n",
      "     44        0.2972  0.1555\n",
      "     45        \u001b[36m0.2844\u001b[0m  0.1962\n",
      "     46        \u001b[36m0.2804\u001b[0m  0.1458\n",
      "     47        \u001b[36m0.2640\u001b[0m  0.1191\n",
      "     48        0.2656  0.1227\n",
      "     49        \u001b[36m0.2555\u001b[0m  0.1236\n",
      "     50        \u001b[36m0.2487\u001b[0m  0.1242\n",
      "     51        \u001b[36m0.2448\u001b[0m  0.1226\n",
      "     52        \u001b[36m0.2370\u001b[0m  0.1176\n",
      "     53        \u001b[36m0.2323\u001b[0m  0.1276\n",
      "     54        \u001b[36m0.2307\u001b[0m  0.1231\n",
      "     55        \u001b[36m0.2245\u001b[0m  0.1256\n",
      "     56        \u001b[36m0.2218\u001b[0m  0.1177\n",
      "     57        0.2241  0.1711\n",
      "     58        \u001b[36m0.2134\u001b[0m  0.1481\n",
      "     59        0.2241  0.1713\n",
      "     60        0.2145  0.1900\n",
      "     61        0.2154  0.2331\n",
      "     62        \u001b[36m0.2092\u001b[0m  0.1531\n",
      "     63        0.2120  0.1415\n",
      "     64        \u001b[36m0.2082\u001b[0m  0.1438\n",
      "     65        \u001b[36m0.2023\u001b[0m  0.1595\n",
      "     66        0.2028  0.1478\n",
      "     67        0.2071  0.1455\n",
      "     68        0.2052  0.1516\n",
      "     69        0.2087  0.1435\n",
      "     70        \u001b[36m0.1995\u001b[0m  0.1381\n",
      "     71        \u001b[36m0.1962\u001b[0m  0.1342\n",
      "     72        0.1983  0.1471\n",
      "     73        \u001b[36m0.1955\u001b[0m  0.1567\n",
      "     74        0.1995  0.1853\n",
      "     75        0.2156  0.1780\n",
      "     76        0.2002  0.1423\n",
      "     77        0.1969  0.1551\n",
      "     78        \u001b[36m0.1920\u001b[0m  0.1581\n",
      "     79        \u001b[36m0.1862\u001b[0m  0.1926\n",
      "     80        \u001b[36m0.1860\u001b[0m  0.2552\n",
      "     81        \u001b[36m0.1856\u001b[0m  0.1932\n",
      "     82        0.1856  0.2302\n",
      "     83        \u001b[36m0.1841\u001b[0m  0.2042\n",
      "     84        \u001b[36m0.1801\u001b[0m  0.2264\n",
      "     85        \u001b[36m0.1770\u001b[0m  0.2743\n",
      "     86        \u001b[36m0.1764\u001b[0m  0.3059\n",
      "     87        \u001b[36m0.1748\u001b[0m  0.2257\n",
      "     88        \u001b[36m0.1712\u001b[0m  0.1923\n",
      "     89        \u001b[36m0.1695\u001b[0m  0.1067\n",
      "     90        \u001b[36m0.1676\u001b[0m  0.1056\n",
      "     91        \u001b[36m0.1650\u001b[0m  0.1176\n",
      "     92        0.1697  0.1256\n",
      "     93        0.1675  0.1112\n",
      "     94        0.1664  0.1142\n",
      "     95        0.1651  0.1147\n",
      "     96        \u001b[36m0.1647\u001b[0m  0.1116\n",
      "     97        0.1687  0.1246\n",
      "     98        \u001b[36m0.1588\u001b[0m  0.1471\n",
      "     99        0.1649  0.1357\n",
      "    100        \u001b[36m0.1559\u001b[0m  0.1036\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1235\n",
      "      3       37.3047  0.2459\n",
      "      4       37.3047  0.1865\n",
      "      5       37.3047  0.1446\n",
      "      6       37.3047  0.1276\n",
      "      7       37.3047  0.1205\n",
      "      8       37.3047  0.1236\n",
      "      9       37.3047  0.1402\n",
      "     10       37.3047  0.1266\n",
      "     11       37.3047  0.1352\n",
      "     12       37.3047  0.1236\n",
      "     13       37.3047  0.1366\n",
      "     14       37.3047  0.0906\n",
      "     15       37.3047  0.0996\n",
      "     16       37.3047  0.1007\n",
      "     17       37.3047  0.1076\n",
      "     18       37.3047  0.1056\n",
      "     19       37.3047  0.0996\n",
      "     20       37.3047  0.1137\n",
      "     21       37.3047  0.1035\n",
      "     22       37.3047  0.1706\n",
      "     23       \u001b[36m35.1446\u001b[0m  0.1713\n",
      "     24        \u001b[36m0.5579\u001b[0m  0.1141\n",
      "     25        \u001b[36m0.5439\u001b[0m  0.1103\n",
      "     26        \u001b[36m0.4934\u001b[0m  0.1106\n",
      "     27        \u001b[36m0.4689\u001b[0m  0.1331\n",
      "     28        \u001b[36m0.4497\u001b[0m  0.1217\n",
      "     29        \u001b[36m0.4257\u001b[0m  0.1176\n",
      "     30        \u001b[36m0.4166\u001b[0m  0.1056\n",
      "     31        \u001b[36m0.3972\u001b[0m  0.1442\n",
      "     32        \u001b[36m0.3884\u001b[0m  0.1526\n",
      "     33        \u001b[36m0.3742\u001b[0m  0.1432\n",
      "     34        \u001b[36m0.3626\u001b[0m  0.1226\n",
      "     35        \u001b[36m0.3536\u001b[0m  0.1566\n",
      "     36        \u001b[36m0.3477\u001b[0m  0.1337\n",
      "     37        \u001b[36m0.3258\u001b[0m  0.1245\n",
      "     38        \u001b[36m0.3208\u001b[0m  0.1909\n",
      "     39        \u001b[36m0.3126\u001b[0m  0.1553\n",
      "     40        \u001b[36m0.3093\u001b[0m  0.1555\n",
      "     41        \u001b[36m0.2906\u001b[0m  0.1337\n",
      "     42        \u001b[36m0.2849\u001b[0m  0.1273\n",
      "     43        \u001b[36m0.2767\u001b[0m  0.1779\n",
      "     44        \u001b[36m0.2662\u001b[0m  0.1456\n",
      "     45        \u001b[36m0.2616\u001b[0m  0.1522\n",
      "     46        \u001b[36m0.2552\u001b[0m  0.1623\n",
      "     47        \u001b[36m0.2457\u001b[0m  0.1492\n",
      "     48        \u001b[36m0.2428\u001b[0m  0.1647\n",
      "     49        \u001b[36m0.2380\u001b[0m  0.1968\n",
      "     50        0.2392  0.2947\n",
      "     51        \u001b[36m0.2357\u001b[0m  0.1748\n",
      "     52        \u001b[36m0.2345\u001b[0m  0.1639\n",
      "     53        \u001b[36m0.2334\u001b[0m  0.2381\n",
      "     54        \u001b[36m0.2315\u001b[0m  0.1888\n",
      "     55        \u001b[36m0.2278\u001b[0m  0.1179\n",
      "     56        \u001b[36m0.2242\u001b[0m  0.1076\n",
      "     57        \u001b[36m0.2201\u001b[0m  0.1276\n",
      "     58        \u001b[36m0.2193\u001b[0m  0.1255\n",
      "     59        \u001b[36m0.2141\u001b[0m  0.1346\n",
      "     60        \u001b[36m0.2104\u001b[0m  0.1591\n",
      "     61        \u001b[36m0.2058\u001b[0m  0.2028\n",
      "     62        \u001b[36m0.2037\u001b[0m  0.2031\n",
      "     63        \u001b[36m0.2037\u001b[0m  0.1571\n",
      "     64        \u001b[36m0.1987\u001b[0m  0.1831\n",
      "     65        \u001b[36m0.1936\u001b[0m  0.1847\n",
      "     66        0.1967  0.1671\n",
      "     67        0.1995  0.1922\n",
      "     68        \u001b[36m0.1930\u001b[0m  0.1551\n",
      "     69        \u001b[36m0.1907\u001b[0m  0.1554\n",
      "     70        \u001b[36m0.1895\u001b[0m  0.1518\n",
      "     71        0.1914  0.1465\n",
      "     72        \u001b[36m0.1806\u001b[0m  0.1482\n",
      "     73        0.1850  0.1236\n",
      "     74        \u001b[36m0.1776\u001b[0m  0.1155\n",
      "     75        0.1836  0.1368\n",
      "     76        0.1792  0.1176\n",
      "     77        0.1830  0.1206\n",
      "     78        0.1792  0.1146\n",
      "     79        \u001b[36m0.1695\u001b[0m  0.1361\n",
      "     80        0.1751  0.1245\n",
      "     81        0.1731  0.1246\n",
      "     82        \u001b[36m0.1675\u001b[0m  0.1134\n",
      "     83        0.1746  0.1126\n",
      "     84        0.1776  0.1330\n",
      "     85        0.1809  0.1285\n",
      "     86        0.1787  0.1627\n",
      "     87        0.1687  0.1424\n",
      "     88        0.1779  0.1269\n",
      "     89        0.1814  0.1140\n",
      "     90        0.1766  0.1155\n",
      "     91        0.1787  0.1136\n",
      "     92        0.1780  0.1245\n",
      "     93        0.1819  0.1126\n",
      "     94        0.1793  0.1186\n",
      "     95        0.1693  0.1172\n",
      "     96        0.1728  0.1103\n",
      "     97        0.1741  0.1136\n",
      "     98        0.1677  0.0996\n",
      "     99        0.1689  0.1036\n",
      "    100        0.1701  0.0957\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1196\n",
      "      3       37.3047  0.1066\n",
      "      4       37.3047  0.1146\n",
      "      5       37.3047  0.1226\n",
      "      6       37.3047  0.1466\n",
      "      7       37.3047  0.1358\n",
      "      8       37.3047  0.1139\n",
      "      9       37.3047  0.1225\n",
      "     10       37.3047  0.1306\n",
      "     11       37.3047  0.1641\n",
      "     12       37.3047  0.1365\n",
      "     13       37.3047  0.0893\n",
      "     14       37.3047  0.1166\n",
      "     15       37.3047  0.1153\n",
      "     16       37.3047  0.1086\n",
      "     17       37.3047  0.1315\n",
      "     18       37.3047  0.1301\n",
      "     19       37.3047  0.1216\n",
      "     20       37.3047  0.1406\n",
      "     21       37.3047  0.1166\n",
      "     22       37.3047  0.1056\n",
      "     23       37.3047  0.1421\n",
      "     24       37.3047  0.1376\n",
      "     25       \u001b[36m16.2481\u001b[0m  0.1743\n",
      "     26        \u001b[36m0.5808\u001b[0m  0.1607\n",
      "     27        \u001b[36m0.5693\u001b[0m  0.1332\n",
      "     28        \u001b[36m0.5604\u001b[0m  0.1196\n",
      "     29        \u001b[36m0.5554\u001b[0m  0.1344\n",
      "     30        \u001b[36m0.5529\u001b[0m  0.1156\n",
      "     31        \u001b[36m0.5490\u001b[0m  0.1219\n",
      "     32        \u001b[36m0.5447\u001b[0m  0.1631\n",
      "     33        \u001b[36m0.4927\u001b[0m  0.1197\n",
      "     34        \u001b[36m0.4586\u001b[0m  0.1596\n",
      "     35        \u001b[36m0.4478\u001b[0m  0.1501\n",
      "     36        \u001b[36m0.4142\u001b[0m  0.1823\n",
      "     37        \u001b[36m0.4052\u001b[0m  0.1416\n",
      "     38        \u001b[36m0.3792\u001b[0m  0.1511\n",
      "     39        \u001b[36m0.3759\u001b[0m  0.1526\n",
      "     40        \u001b[36m0.3496\u001b[0m  0.1482\n",
      "     41        \u001b[36m0.3334\u001b[0m  0.1800\n",
      "     42        \u001b[36m0.3184\u001b[0m  0.1749\n",
      "     43        \u001b[36m0.3164\u001b[0m  0.1296\n",
      "     44        \u001b[36m0.3007\u001b[0m  0.1206\n",
      "     45        \u001b[36m0.2909\u001b[0m  0.1456\n",
      "     46        \u001b[36m0.2887\u001b[0m  0.1431\n",
      "     47        \u001b[36m0.2841\u001b[0m  0.1505\n",
      "     48        \u001b[36m0.2775\u001b[0m  0.1501\n",
      "     49        \u001b[36m0.2747\u001b[0m  0.1446\n",
      "     50        0.2771  0.1442\n",
      "     51        0.2785  0.1376\n",
      "     52        0.2750  0.1361\n",
      "     53        0.2784  0.1776\n",
      "     54        \u001b[36m0.2738\u001b[0m  0.1432\n",
      "     55        0.2758  0.1922\n",
      "     56        0.2877  0.3188\n",
      "     57        0.2798  0.1695\n",
      "     58        0.2794  0.1451\n",
      "     59        \u001b[36m0.2638\u001b[0m  0.2052\n",
      "     60        0.2640  0.2428\n",
      "     61        \u001b[36m0.2611\u001b[0m  0.1776\n",
      "     62        \u001b[36m0.2546\u001b[0m  0.2311\n",
      "     63        \u001b[36m0.2500\u001b[0m  0.1396\n",
      "     64        \u001b[36m0.2439\u001b[0m  0.1852\n",
      "     65        \u001b[36m0.2415\u001b[0m  0.1392\n",
      "     66        0.2482  0.1176\n",
      "     67        \u001b[36m0.2397\u001b[0m  0.1075\n",
      "     68        \u001b[36m0.2368\u001b[0m  0.1185\n",
      "     69        0.2395  0.1336\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m37.3047\u001b[0m  0.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:18: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense0.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:22: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense1.weight)\n",
      "C:\\Users\\wiwil\\AppData\\Local\\Temp\\ipykernel_19396\\83687862.py:25: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  torch.nn.init.uniform(self.dense2.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       37.3047  0.1672\n",
      "      3       37.3047  0.1559\n",
      "      4       37.3047  0.1677\n",
      "      5       37.3047  0.1446\n",
      "      6       37.3047  0.2447\n",
      "      7       37.3047  0.1386\n",
      "      8       37.3047  0.1413\n",
      "      9       37.3047  0.1717\n",
      "     10       37.3047  0.1221\n",
      "     11       37.3047  0.1126\n",
      "     12       37.3047  0.1276\n",
      "     13       37.3047  0.1332\n",
      "     14       37.3047  0.1331\n",
      "     15       37.3047  0.1496\n",
      "     16       37.3047  0.1613\n",
      "     17       37.3047  0.1345\n",
      "     18       37.3047  0.2112\n",
      "     19       37.3047  0.2644\n",
      "     20       37.3047  0.1496\n",
      "     21       37.3047  0.1497\n",
      "     22       37.3047  0.2012\n",
      "     23       \u001b[36m12.7908\u001b[0m  0.2389\n",
      "     24        \u001b[36m0.5656\u001b[0m  0.2048\n",
      "     25        \u001b[36m0.5195\u001b[0m  0.1605\n",
      "     26        \u001b[36m0.4931\u001b[0m  0.1931\n",
      "     27        \u001b[36m0.4548\u001b[0m  0.1611\n",
      "     28        \u001b[36m0.4263\u001b[0m  0.1732\n",
      "     29        \u001b[36m0.4036\u001b[0m  0.1556\n",
      "     30        \u001b[36m0.3794\u001b[0m  0.2102\n",
      "     31        \u001b[36m0.3631\u001b[0m  0.2968\n",
      "     32        \u001b[36m0.3460\u001b[0m  0.2007\n",
      "     33        \u001b[36m0.3366\u001b[0m  0.1463\n",
      "     34        \u001b[36m0.3270\u001b[0m  0.1526\n",
      "     35        \u001b[36m0.3167\u001b[0m  0.2072\n",
      "     36        \u001b[36m0.3086\u001b[0m  0.1427\n",
      "     37        \u001b[36m0.2983\u001b[0m  0.1562\n",
      "     38        \u001b[36m0.2909\u001b[0m  0.1467\n",
      "     39        \u001b[36m0.2863\u001b[0m  0.1808\n",
      "     40        \u001b[36m0.2766\u001b[0m  0.1741\n",
      "     41        \u001b[36m0.2675\u001b[0m  0.1866\n",
      "     42        \u001b[36m0.2618\u001b[0m  0.1730\n",
      "     43        \u001b[36m0.2587\u001b[0m  0.1611\n",
      "     44        \u001b[36m0.2483\u001b[0m  0.1436\n",
      "     45        \u001b[36m0.2437\u001b[0m  0.2432\n",
      "     46        \u001b[36m0.2398\u001b[0m  0.1864\n",
      "     47        \u001b[36m0.2318\u001b[0m  0.2288\n",
      "     48        \u001b[36m0.2263\u001b[0m  0.2959\n",
      "     49        \u001b[36m0.2201\u001b[0m  0.3309\n",
      "     50        \u001b[36m0.2114\u001b[0m  0.2237\n",
      "     51        \u001b[36m0.2100\u001b[0m  0.2211\n",
      "     52        \u001b[36m0.1994\u001b[0m  0.2401\n",
      "     53        \u001b[36m0.1983\u001b[0m  0.1582\n",
      "     54        \u001b[36m0.1919\u001b[0m  0.2101\n",
      "     55        \u001b[36m0.1819\u001b[0m  0.2567\n",
      "     56        0.1820  0.1873\n",
      "     57        \u001b[36m0.1795\u001b[0m  0.1662\n",
      "     58        0.1821  0.1374\n",
      "     59        \u001b[36m0.1743\u001b[0m  0.1383\n",
      "     60        \u001b[36m0.1694\u001b[0m  0.1451\n",
      "     61        \u001b[36m0.1692\u001b[0m  0.1452\n",
      "     62        \u001b[36m0.1596\u001b[0m  0.1762\n",
      "     63        \u001b[36m0.1587\u001b[0m  0.1673\n",
      "     64        0.1601  0.1442\n",
      "     65        \u001b[36m0.1537\u001b[0m  0.1264\n",
      "     66        \u001b[36m0.1517\u001b[0m  0.1652\n",
      "     67        0.1525  0.2307\n"
     ]
    }
   ],
   "source": [
    "result = cross_val_score(classificador_sklearn, previsores, classe, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media 0.806704260651629\n",
      "desvio 0.12251488513561204\n"
     ]
    }
   ],
   "source": [
    "media = result.mean()\n",
    "print(\"media\",media)\n",
    "print(\"desvio\", result.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
