{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd -  2.0.3\n",
      "sklearn -  1.5.1\n",
      "np -  1.23.5\n",
      "sns -  0.13.2\n",
      "sklearn -  1.5.1\n",
      "torch -  2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"pd - \", pd.__version__) \n",
    "print(\"sklearn - \", sklearn.__version__) \n",
    "print(\"np - \", np.__version__) \n",
    "print(\"sns - \", sns.__version__) \n",
    "print(\"sklearn - \", sklearn.__version__) \n",
    "print(\"torch - \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)  # Semente da aleatoriedade.\n",
    "torch.manual_seed(123)  # Para os pesos da rede começar sempre iguais (BOA PRÁTICA).\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "baseFolder = os.path.join(os.path.dirname(os.getcwd()),\"Bases\")\n",
    "\n",
    "previsoresData = os.path.join(baseFolder, \"entradas_breast.csv\")\n",
    "classeData = os.path.join(baseFolder, \"saidas_breast.csv\")\n",
    "\n",
    "previsores = pd.read_csv(previsoresData)  # Caracteristicas do tumor\n",
    "classe = pd.read_csv(classeData)  # Maligno ou benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = torch.tensor(np.array(previsores), dtype=torch.float)\n",
    "classes = torch.tensor(np.array(classe), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.TensorDataset(previsores, classes),\n",
    "                          batch_size=10, \n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo\n",
    "class classificador_torch(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inicialização dos pesos\n",
    "        self.dense0 = torch.nn.Linear(30, 8)\n",
    "        torch.nn.init.normal_(self.dense0.weight, mean = 0.0, std=0.05)  # Faz a inicialização dos pesos levando em ocnsideração o desvio.\n",
    "        self.dense1 = torch.nn.Linear(8, 8)\n",
    "        torch.nn.init.normal_(self.dense0.weight, mean = 0.0, std=0.05)\n",
    "        self.dense2 = torch.nn.Linear(8, 1)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.output = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dense0(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        output = self.output(x)\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = classificador_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÉPOCH 1, 16.843043593591766\n",
      "ÉPOCH 2, 1.8109540879203563\n",
      "ÉPOCH 3, 0.7080962501074138\n",
      "ÉPOCH 4, 0.670868156249063\n",
      "ÉPOCH 5, 0.6516150497553641\n",
      "ÉPOCH 6, 0.6161274690377084\n",
      "ÉPOCH 7, 0.6120375598731794\n",
      "ÉPOCH 8, 0.5925950977885932\n",
      "ÉPOCH 9, 0.5915186033959974\n",
      "ÉPOCH 10, 0.5578441002912689\n",
      "ÉPOCH 11, 0.5748710710751382\n",
      "ÉPOCH 12, 0.5793091424724512\n",
      "ÉPOCH 13, 0.5886205063577283\n",
      "ÉPOCH 14, 0.5657687176737869\n",
      "ÉPOCH 15, 0.5801995495955149\n",
      "ÉPOCH 16, 0.5666103661060333\n",
      "ÉPOCH 17, 0.5705412631494957\n",
      "ÉPOCH 18, 0.5876957470910591\n",
      "ÉPOCH 19, 0.5645796635694671\n",
      "ÉPOCH 20, 0.5616445645951388\n",
      "ÉPOCH 21, 0.5617436980992033\n",
      "ÉPOCH 22, 0.5573642478700269\n",
      "ÉPOCH 23, 0.5532874773468888\n",
      "ÉPOCH 24, 0.5574886788401687\n",
      "ÉPOCH 25, 0.5649689237276713\n",
      "ÉPOCH 26, 0.5569732586542765\n",
      "ÉPOCH 27, 0.5485042270861173\n",
      "ÉPOCH 28, 0.5368118803752097\n",
      "ÉPOCH 29, 0.5520796247741633\n",
      "ÉPOCH 30, 0.5505548062031729\n",
      "ÉPOCH 31, 0.5490319258288333\n",
      "ÉPOCH 32, 0.5403958140758046\n",
      "ÉPOCH 33, 0.5445332898382556\n",
      "ÉPOCH 34, 0.5446286949149349\n",
      "ÉPOCH 35, 0.530074651826892\n",
      "ÉPOCH 36, 0.5415015202342418\n",
      "ÉPOCH 37, 0.5412953794002533\n",
      "ÉPOCH 38, 0.5409995448171047\n",
      "ÉPOCH 39, 0.5410133934857553\n",
      "ÉPOCH 40, 0.5426487833784338\n",
      "ÉPOCH 41, 0.5232940661279779\n",
      "ÉPOCH 42, 0.5251153916643377\n",
      "ÉPOCH 43, 0.5417540277305403\n",
      "ÉPOCH 44, 0.5541805473336002\n",
      "ÉPOCH 45, 0.5263572465955165\n",
      "ÉPOCH 46, 0.5372079521940466\n",
      "ÉPOCH 47, 0.5403975216965926\n",
      "ÉPOCH 48, 0.5434366678982451\n",
      "ÉPOCH 49, 0.5277657127171232\n",
      "ÉPOCH 50, 0.5272157500710404\n",
      "ÉPOCH 51, 0.5135415423857538\n",
      "ÉPOCH 52, 0.5224032885672754\n",
      "ÉPOCH 53, 0.5345575919276789\n",
      "ÉPOCH 54, 0.5116368202786696\n",
      "ÉPOCH 55, 0.5304337716416309\n",
      "ÉPOCH 56, 0.5115741606344256\n",
      "ÉPOCH 57, 0.511729953058979\n",
      "ÉPOCH 58, 0.5068473512666267\n",
      "ÉPOCH 59, 0.4995532639716801\n",
      "ÉPOCH 60, 0.5022984716975898\n",
      "ÉPOCH 61, 0.5097110538106215\n",
      "ÉPOCH 62, 0.49941646477632357\n",
      "ÉPOCH 63, 0.47274396215614517\n",
      "ÉPOCH 64, 0.5201261974217599\n",
      "ÉPOCH 65, 0.49243208399990146\n",
      "ÉPOCH 66, 0.4803466890987597\n",
      "ÉPOCH 67, 0.4649158344979872\n",
      "ÉPOCH 68, 0.4896838068962097\n",
      "ÉPOCH 69, 0.4802874141094977\n",
      "ÉPOCH 70, 0.4755969996515073\n",
      "ÉPOCH 71, 0.4618451161342755\n",
      "ÉPOCH 72, 0.45949988616140264\n",
      "ÉPOCH 73, 0.4799303527463946\n",
      "ÉPOCH 74, 0.4910986094098342\n",
      "ÉPOCH 75, 0.47752125848803606\n",
      "ÉPOCH 76, 0.45145405253820253\n",
      "ÉPOCH 77, 0.44186273321770786\n",
      "ÉPOCH 78, 0.45544522948432387\n",
      "ÉPOCH 79, 0.42925091218530087\n",
      "ÉPOCH 80, 0.4594676405714269\n",
      "ÉPOCH 81, 0.4563110245947252\n",
      "ÉPOCH 82, 0.4030823321326783\n",
      "ÉPOCH 83, 0.4593589462732014\n",
      "ÉPOCH 84, 0.44237502180693444\n",
      "ÉPOCH 85, 0.4239839257901175\n",
      "ÉPOCH 86, 0.4079994101796234\n",
      "ÉPOCH 87, 0.3973729197393384\n",
      "ÉPOCH 88, 0.48138039284630824\n",
      "ÉPOCH 89, 0.44115422953639116\n",
      "ÉPOCH 90, 0.45615167889678687\n",
      "ÉPOCH 91, 0.45034503832198025\n",
      "ÉPOCH 92, 0.41597498234426766\n",
      "ÉPOCH 93, 0.4421028902656154\n",
      "ÉPOCH 94, 0.43020547534290116\n",
      "ÉPOCH 95, 0.40975522890425564\n",
      "ÉPOCH 96, 0.42522464143602473\n",
      "ÉPOCH 97, 0.42516805623707016\n",
      "ÉPOCH 98, 0.4274887296191433\n",
      "ÉPOCH 99, 0.4182062933319493\n",
      "ÉPOCH 100, 0.429681549273562\n",
      "ÉPOCH 101, 0.41691556677483677\n",
      "ÉPOCH 102, 0.4057629811659194\n",
      "ÉPOCH 103, 0.423378970016513\n",
      "ÉPOCH 104, 0.4118038719160515\n",
      "ÉPOCH 105, 0.40702722888243825\n",
      "ÉPOCH 106, 0.40665428366577416\n",
      "ÉPOCH 107, 0.4093340546415563\n",
      "ÉPOCH 108, 0.4112956963087383\n",
      "ÉPOCH 109, 0.43256257866558273\n",
      "ÉPOCH 110, 0.42913793654818283\n",
      "ÉPOCH 111, 0.418098572837679\n",
      "ÉPOCH 112, 0.43233416660835866\n",
      "ÉPOCH 113, 0.4403477352962159\n",
      "ÉPOCH 114, 0.43933262388434324\n",
      "ÉPOCH 115, 0.4593723659452639\n",
      "ÉPOCH 116, 0.3933850568637513\n",
      "ÉPOCH 117, 0.40081572519582614\n",
      "ÉPOCH 118, 0.39498133983528405\n",
      "ÉPOCH 119, 0.3901010226262243\n",
      "ÉPOCH 120, 0.4225038906984162\n",
      "ÉPOCH 121, 0.4156319067666405\n",
      "ÉPOCH 122, 0.412636162811204\n",
      "ÉPOCH 123, 0.399417602702191\n",
      "ÉPOCH 124, 0.38503435384808926\n",
      "ÉPOCH 125, 0.40421832261378304\n",
      "ÉPOCH 126, 0.38434747149024096\n",
      "ÉPOCH 127, 0.3987245439437398\n",
      "ÉPOCH 128, 0.34231534639471456\n",
      "ÉPOCH 129, 0.3653476137602538\n",
      "ÉPOCH 130, 0.3600221888015145\n",
      "ÉPOCH 131, 0.32215865047877296\n",
      "ÉPOCH 132, 0.3542020516960244\n",
      "ÉPOCH 133, 0.307883519613952\n",
      "ÉPOCH 134, 0.3099427222552007\n",
      "ÉPOCH 135, 0.3132794711804181\n",
      "ÉPOCH 136, 0.31717821328263535\n",
      "ÉPOCH 137, 0.3119440217290008\n",
      "ÉPOCH 138, 0.32538959370893344\n",
      "ÉPOCH 139, 0.3179884441850478\n",
      "ÉPOCH 140, 0.33316137759309067\n",
      "ÉPOCH 141, 0.3119090425602177\n",
      "ÉPOCH 142, 0.3155080795026662\n",
      "ÉPOCH 143, 0.3049225715691583\n",
      "ÉPOCH 144, 0.27267366758825484\n",
      "ÉPOCH 145, 0.26462936229807765\n",
      "ÉPOCH 146, 0.2887386799904338\n",
      "ÉPOCH 147, 0.32016475224181223\n",
      "ÉPOCH 148, 0.2905609941011981\n",
      "ÉPOCH 149, 0.3025666713191752\n",
      "ÉPOCH 150, 0.2862359784674226\n"
     ]
    }
   ],
   "source": [
    "# Treinamento do modelo.\n",
    "for epoch in range(150):\n",
    "    \n",
    "    runnin_loss = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # Zera gradiente \n",
    "        \n",
    "        outputs = classificador(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # Pega erro com base na predição e dados reais\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        runnin_loss += loss.item()\n",
    "        \n",
    "    print(f\"ÉPOCH {epoch + 1}, {runnin_loss/ len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('dense0.weight',\n",
       "              tensor([[-4.9899e-03,  2.3418e-04, -5.1511e-03, -1.2797e-03, -6.5552e-02,\n",
       "                        5.7504e-03,  3.1799e-02, -1.4916e-02, -4.8228e-02, -2.0683e-02,\n",
       "                       -3.8868e-03, -1.2680e-02, -2.1246e-02,  4.1091e-02, -2.2961e-17,\n",
       "                        1.6953e-16,  9.6646e-18, -4.3198e-12,  7.4416e-03,  4.6670e-17,\n",
       "                        3.4795e-02, -8.0554e-02, -5.5831e-02, -2.6519e-02, -1.0744e-04,\n",
       "                       -2.4288e-03,  3.7040e-03, -1.2666e-02,  1.2023e-02, -1.7501e-03],\n",
       "                      [-4.8514e-01, -3.3041e-01, -3.7431e-01, -7.0810e-02,  1.2922e-01,\n",
       "                        1.1530e-01,  1.1160e-01, -1.4833e-01, -9.2875e-03,  1.0691e-01,\n",
       "                       -9.3235e-03,  2.8159e-04,  3.5821e-03, -2.6402e-02,  4.6819e-03,\n",
       "                       -1.5240e-01,  4.0917e-02, -2.1008e-01,  4.7321e-01,  1.4853e-01,\n",
       "                       -3.4961e-01, -2.9083e-01, -2.9016e-01,  1.6122e-01,  2.0231e-03,\n",
       "                        4.0435e-02, -6.8788e-03,  1.4066e-01,  1.5006e-03,  6.3644e-01],\n",
       "                      [ 7.7211e-02,  2.1257e-01,  4.2941e-01,  1.0372e-01, -2.3374e-01,\n",
       "                       -1.9018e-01,  1.2976e-01,  1.7092e-02,  3.1201e-03,  3.5922e-01,\n",
       "                       -4.0125e-02, -1.2400e-01,  1.4007e-03, -1.0492e-01, -1.1567e-02,\n",
       "                       -3.0366e-01,  1.1763e-01,  9.9291e-02,  6.0442e-01, -1.3132e-02,\n",
       "                        6.9746e-02,  5.8133e-02,  2.6701e-01, -1.6280e-01,  4.1179e-02,\n",
       "                       -1.4337e-02, -1.4289e-02, -2.7130e-03, -2.2891e-02, -7.5280e-02],\n",
       "                      [ 2.5165e-02,  3.0086e-01,  1.8453e-01,  2.9969e-02,  1.9797e-02,\n",
       "                       -1.8570e-01, -1.3544e-01,  3.3308e-01,  1.5418e-01,  9.3281e-02,\n",
       "                       -5.5853e-04, -1.5919e-02, -1.4815e-01, -2.5963e-01,  1.5067e-03,\n",
       "                        1.8083e-01, -6.7949e-02,  4.2280e-01, -2.1852e-01, -1.0097e-02,\n",
       "                        9.1622e-03,  2.5321e-01,  1.5917e-01, -1.0797e-01,  4.4008e-02,\n",
       "                        9.6437e-02,  1.3826e-01, -5.5148e-02,  7.2662e-02, -9.3206e-02],\n",
       "                      [ 2.1316e-01,  2.4216e-01,  3.8519e-01,  3.0706e-02, -2.2651e-01,\n",
       "                        8.7899e-02, -1.0037e-01,  5.0555e-01,  2.1352e-01, -4.4095e-01,\n",
       "                       -2.7547e-02,  3.0252e-02, -9.1065e-03, -2.3158e-01, -2.8200e-03,\n",
       "                        4.6625e-01,  3.8158e-01, -2.3481e-02, -4.4723e-01, -5.0183e-01,\n",
       "                        1.3035e-01,  1.3642e-02,  1.8018e-01, -1.2641e-01, -2.0576e-01,\n",
       "                        6.6373e-02, -1.2985e-01,  1.1748e-01,  6.3990e-03, -3.4135e-01],\n",
       "                      [-5.1659e-02, -1.1066e-01, -4.2458e-02, -1.2681e-01, -4.4428e-02,\n",
       "                       -4.7418e-02, -1.6201e-02, -1.9053e-02, -1.1474e-02, -1.0611e-03,\n",
       "                       -1.8007e-02, -5.9535e-06,  1.9250e-02, -4.7697e-02,  2.0698e-39,\n",
       "                        1.0568e-11, -1.5051e-39, -1.5124e-11,  4.3084e-08,  2.9280e-05,\n",
       "                       -1.2592e-01, -9.3538e-02, -3.1857e-02, -6.6196e-02, -3.7259e-02,\n",
       "                        1.3020e-02, -2.5323e-02, -2.4828e-02,  9.9375e-03, -6.1450e-02],\n",
       "                      [ 1.1757e-01, -7.8888e-03, -4.7618e-02, -5.4248e-02, -7.4068e-03,\n",
       "                       -8.2578e-05, -9.5970e-03, -6.7095e-03,  1.1387e-01, -9.4738e-07,\n",
       "                        1.2030e-02, -1.2537e-02, -3.5441e-02,  7.2645e-02,  2.9364e-15,\n",
       "                       -5.2037e-15, -5.3958e-03,  2.6575e-15,  5.1927e-06,  5.2506e-15,\n",
       "                        4.5338e-02, -6.0339e-02, -2.4046e-02, -1.2203e-02,  1.9000e-02,\n",
       "                       -1.0507e-02, -6.1087e-02,  8.5925e-03,  4.6850e-03,  5.3506e-07],\n",
       "                      [-2.8641e-01, -2.6438e-01, -2.4075e-01,  2.2588e-02,  3.9856e-02,\n",
       "                        2.5124e-01,  1.1650e-01, -3.1408e-01, -4.7179e-02,  1.7554e-01,\n",
       "                        3.7777e-02, -1.5334e-03, -6.8119e-02, -3.0358e-02,  4.3876e-04,\n",
       "                       -1.4107e-01,  8.3169e-02, -2.3462e-01,  5.7879e-01,  4.3293e-03,\n",
       "                       -2.3939e-01, -3.1775e-01, -1.7512e-01,  8.0873e-02, -7.9544e-02,\n",
       "                       -9.0591e-02, -1.3676e-01,  2.1682e-01, -4.7964e-02,  3.0111e-01]])),\n",
       "             ('dense0.bias',\n",
       "              tensor([ 4.8403e-07, -5.7196e-01,  6.9307e-01,  3.2398e-01,  8.5217e-01,\n",
       "                       8.7933e-04, -3.9232e-06, -4.0727e-01])),\n",
       "             ('dense1.weight',\n",
       "              tensor([[ 0.2391, -0.0530, -0.1355, -0.0677,  0.0977,  0.1180,  0.0543, -0.0798],\n",
       "                      [-0.0111,  0.0936, -0.1588, -0.1360, -0.2971,  0.0436, -0.0193,  0.0580],\n",
       "                      [-0.0840, -0.3760,  0.3332,  0.4984,  0.1996,  0.3122,  0.1526, -0.1571],\n",
       "                      [ 0.0305, -0.3280, -0.1600, -0.1670, -0.3254,  0.2189, -0.0971, -0.2590],\n",
       "                      [ 0.0960, -0.0764, -0.1733, -0.0706, -0.1240,  0.2552,  0.0533, -0.0014],\n",
       "                      [ 0.1942, -0.1276,  0.2632,  0.3161,  0.0759, -0.0975,  0.0318, -0.3390],\n",
       "                      [ 0.2112, -0.0351,  0.5364,  0.2820,  0.1853,  0.1536,  0.1346, -0.2203],\n",
       "                      [-0.0137,  0.1763, -0.1273, -0.1110, -0.1262,  0.0264, -0.0452,  0.1561]])),\n",
       "             ('dense1.bias',\n",
       "              tensor([ 0.3148,  0.2546,  0.3175,  0.6763, -0.0053,  0.2745,  0.3180,  0.2672])),\n",
       "             ('dense2.weight',\n",
       "              tensor([[ 0.1746, -0.3733,  0.1210, -0.1402,  0.1705,  0.2547,  0.1256, -0.1935]])),\n",
       "             ('dense2.bias', tensor([0.3105]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pesos da rede\n",
    "classificador.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classificador.state_dict(), \"classificador.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
